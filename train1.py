# -*- coding: utf-8 -*-
"""conv lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pk_9y1txgv_KprxWLG0C-PkaUjAF-E3J

# Installation
"""

import logging 
logging.basicConfig(filename="std5.log", 
					format='%(asctime)s %(message)s', 
					filemode='w')

                    

logger=logging.getLogger() 
logger.setLevel(logging.DEBUG) 
import torch 
import cv2
import random
import numpy as np 
from torch import nn 
from tqdm import tqdm
from segmentation_models_pytorch.losses import DiceLoss, LovaszLoss, FocalLoss, JaccardLoss
import glob
import matplotlib.pyplot as plt
import pandas as pd
#from networks import SegmentationModel, ConvLSTMCell, UnetInitialiser, Network
from networks import SegmentationModel, ConvLSTMCell
from dataloader import get_train_augs, get_test_augs, get_valid_augs, SegmentationDataset
#from training_functions import train_function, eval_function
DEVICE = torch.device('cuda') 
# DEVICE = 'cuda' #Cuda as using GPU



EPOCHS = 50 #25 training iterations
LR = 0.00001 #decay learning rate
BATCH_SIZE = 4
HEIGHT = 288
WIDTH = 480
ENCODER = 'resnet34'
WEIGHTS = 'imagenet'
DATA_URL = "/cs/student/projects1/2019/nsultana/"


training_images = (glob.glob(f"{DATA_URL}new_data/Training1/*.npz"))



testing_images = (glob.glob(f"{DATA_URL}new_data/Testing/*.npz"))

validation_images = (glob.glob(f"{DATA_URL}new_data/Validation/*.npz"))

"""# Set up model"""


model = SegmentationModel()
model = model.to(device =DEVICE); #i.e CUDA


"""# Set up dataset and data loader"""



trainset = SegmentationDataset("Training", get_train_augs(), training_images)
validset = SegmentationDataset("Validation", get_valid_augs(), validation_images)
testset = SegmentationDataset("Testing", get_test_augs(), testing_images)

from torch.utils.data import DataLoader
trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True,num_workers=2) #every epoch batches shuffles
validloader = DataLoader(validset, batch_size = BATCH_SIZE, shuffle = True,num_workers=2)




"""# Training model"""

#model.load_state_dict(torch.load(f'{DATA_URL}Models/best_model_aug.pt'))
model_summary = model.show()
encoder = model_summary.encoder
decoder = model_summary.decoder
head = model_summary.segmentation_head

def calculate_weights(masks):
    labels = [0,1,2,3,4,5,6,7]
    weights_list = dict.fromkeys(labels,0)
    new_weights = []
    max_weights = dict.fromkeys(labels,0)
    ground_truth = masks.to('cpu').flatten().numpy().astype(int)

    total_weight = 0
    for label in labels:
        count = (ground_truth == label).sum()
        weights_list[label] += count
        total_weight +=count
    
    for label in labels:
        weight = weights_list[label]
        if weight == 0:
            new_weights.append(0)
        else:
            new_weights.append(1 - (weight/total_weight))

    return new_weights

class ConvLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers,
                 encoder, decoder, head):
        super(ConvLSTM, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        layers = []
        for i in range(0, self.num_layers):
            layers.append(ConvLSTMCell(input_size = self.input_size, hidden_size = self.hidden_size))

        self.layers = nn.ModuleList(layers)
        self.encoder = encoder
        self.decoder = decoder
        self.head = head

    def forward(self, images, masks):
        length = images.shape[1] - 2
        image_0 = images[:,0,:,:,:]
        image_1 = images[:,1,:,:,:]
        image_2 = images[:,2,:,:,:]
        if masks!=None:
            mask = masks[:,2,:,:]
            mask = mask.contiguous().long()


        fv1 = self.encoder(image_0)
        fv2 = self.encoder(image_1)
        x_tilda = self.encoder(image_2)



        c0 = fv1[5]
        h0 = fv2[5]
        feature_vectors = []
        x_tilda = self.encoder(image_2)
        feature_vector = x_tilda[5]
        
        layer_output_list = []
        x_tildas = []
        for i in range(0, length):
            
            x_tilda = self.encoder(images[:,i+2,:,:,:])
            feature_vectors.append(x_tilda[5])
            
            x_tildas.append(x_tilda)
            feature_vector = x_tilda[5]
            

        feature_vectors = torch.stack(feature_vectors)
        cur_layer_input = feature_vectors

        for layer_idx in range(self.num_layers):

            h = h0
            c = c0
            output_inner = []
            for i in range(0,length):
                
                h, c = self.layers[layer_idx](input_=cur_layer_input[i,:, :, :, :],
                                                    hiddenState=h, cellState=c)
                output_inner.append(h)
                

            
            layer_output = torch.stack(output_inner, dim=0)
            cur_layer_input = layer_output
            

            # layer_output_list.append(layer_output)
            # last_state_list.append([h, c])
        logits = []
        ce_weights = calculate_weights(masks)
        ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
        weights = [0.1, 0.25, 0.5, 0.25, 0.1]
        # weights = [0.2, 0.2, 0.2, 0.2, 0.2]
        loss = 0
        losses = []
        # cell_loss = nn.MSELoss()
        
        for i in range(0, len(x_tildas)):
            
            
            h = cur_layer_input[i,:,:,:,:]
            x_tilda = x_tildas[i]
            x_tilda[5] = h
            mask = masks[:,i+2,:,:]
            mask = mask.contiguous()

            decoder_output = self.decoder(*x_tilda)
            logits_mask = self.head(decoder_output)

            lovasz = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logits_mask, mask)
        
            criterion = nn.CrossEntropyLoss(weight = ce_weights, ignore_index=-1)
            ce_logit = criterion(logits_mask, mask)
            # loss = loss + (lovasz + ce_logit) * weights[i]
            losses.append((lovasz + ce_logit) * weights[i])
            # hidden_loss = nn.MSELoss()
            # cell_loss = nn.MSELoss()

            # hidden_state_loss = hidden_loss(h, h0) 
            # cell_state_loss = cell_loss(c, c0)

        loss = sum(losses)
        return loss, logits_mask

class Network2(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers,
                 encoder, decoder, head, initialiser):
        super(Network2, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        layers = []
        for i in range(0, self.num_layers):
            layers.append(ConvLSTMCell(input_size = self.input_size, hidden_size = self.hidden_size))

        self.layers = nn.ModuleList(layers)
        self.encoder = encoder
        self.decoder = decoder
        self.head = head
        self.initialiser = initialiser
    def forward(self, images, masks):
        length = images.shape[1] - 3

        for i in range(0, length):
            
            x_tilda = self.encoder(image_2)
            feature_vectors.append(x_tilda[5])
            
            x_tildas.append(x_tilda)
            feature_vector = x_tilda[5]
            

        feature_vectors = torch.stack(feature_vectors)
        cur_layer_input = feature_vectors

        for layer_idx in range(self.num_layers):

            h = h0
            c = c0
            output_inner = []
            for i in range(0,length):
                
                h, c = self.layers[layer_idx](input_=cur_layer_input[i,:, :, :, :],
                                                    hiddenState=h, cellState=c)
                output_inner.append(h)
                h_next = h
                c_next = c

            
            layer_output = torch.stack(output_inner, dim=0)
            cur_layer_input = layer_output
            

            # layer_output_list.append(layer_output)
            # last_state_list.append([h, c])
        logits = []
        ce_weights = calculate_weights(masks)
        ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
        weights = [0.1, 0.2, 0.4, 0.2, 0.1]
        loss = 0
        # cell_loss = nn.MSELoss()
        for i in range(0, len(x_tildas)):
            
            
            h = cur_layer_input[i,:,:,:,:]
            x_tilda = x_tildas[i]
            x_tilda[5] = h
            mask = masks[:,i+2,:,:]
            mask = mask.contiguous()

            decoder_output = self.decoder(*x_tilda)
            logits_mask = self.head(decoder_output)

            lovasz = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logits_mask, mask)
        
            criterion = nn.CrossEntropyLoss(weight = ce_weights, ignore_index=-1)
            ce_logit = criterion(logits_mask, mask)
            loss = loss + (lovasz + ce_logit) * weights[i]

            # hidden_loss = nn.MSELoss()
            # cell_loss = nn.MSELoss()

            # hidden_state_loss = hidden_loss(h, h0) 
            # cell_state_loss = cell_loss(c, c0)

        # loss = (lovasz_loss + cross_entropy_loss + (cell_state_loss) + hidden_state_loss)
        return loss, logits_mask

# class ConvLSTM(nn.Module):
#     def __init__(self, input_size, hidden_size, num_layers,
#                  encoder, decoder, head, initialiser):
#         super(ConvLSTM, self).__init__()
#         self.input_size = input_size
#         self.hidden_size = hidden_size
#         self.num_layers = num_layers
#         layers = []
#         for i in range(0, self.num_layers):
#             layers.append(ConvLSTMCell(input_size = self.input_size, hidden_size = self.hidden_size))

#         self.layers = nn.ModuleList(layers)
#         self.encoder = encoder
#         self.decoder = decoder
#         self.head = head
#         self.initialiser = initialiser

#     def forward(self, images, masks):
#         length = images.shape[1] - 2
#         image_0 = images[:,0,:,:,:]
#         image_1 = images[:,1,:,:,:]
#         image_2 = images[:,2,:,:,:]
#         if masks!=None:
#             mask = masks[:,2,:,:]
#             mask = mask.contiguous().long()


#         fv1 = self.encoder(image_0)
#         fv2 = self.encoder(image_1)
#         x_tilda = self.encoder(image_2)



#         c0 = fv1[5]
#         h0 = fv2[5]
#         feature_vectors = []
#         x_tilda = self.encoder(image_2)
#         feature_vector = x_tilda[5]
        
#         layer_output_list = []
#         x_tildas = []
#         for i in range(0, length):
            
#             x_tilda = self.encoder(image_2)
#             feature_vectors.append(x_tilda[5])
            
#             x_tildas.append(x_tilda)
#             feature_vector = x_tilda[5]
            

#         feature_vectors = torch.stack(feature_vectors)
#         cur_layer_input = feature_vectors

#         for layer_idx in range(self.num_layers):

#             h = h0
#             c = c0
#             output_inner = []
#             for i in range(0,length):
                
#                 h, c = self.layers[layer_idx](x=cur_layer_input[i,:, :, :, :],
#                                                     h=h, c=c)
#                 output_inner.append(h)
               

#             layer_output = torch.stack(output_inner, dim=0)
#             cur_layer_input = layer_output
            

#             # layer_output_list.append(layer_output)
#             # last_state_list.append([h, c])
#         logits = []
#         ce_weights = calculate_weights(masks)
#         ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
#         for i in range(0, len(x_tildas)):
            
#             h = cur_layer_input[i,:,:,:,:]
#             x_tilda = x_tildas[i]
#             x_tilda[5] = h

#             decoder_output = self.decoder(*x_tilda)
#             logits_mask = self.head(decoder_output)

#             lovasz_loss = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logits_mask, mask)

        
#             criterion = nn.CrossEntropyLoss(weight = ce_weights, ignore_index=-1)
#             cross_entropy_loss = criterion(logits_mask, mask)

#             hidden_loss = nn.MSELoss()
#             cell_loss = nn.MSELoss()

#             hidden_state_loss = hidden_loss(h, h0) 
#             cell_state_loss = cell_loss(c, c0)

#         loss = (lovasz_loss + cross_entropy_loss + (cell_state_loss) + hidden_state_loss)
#         return c, h, logits_mask, loss



class Network(nn.Module):
        def __init__(self, initializer, encoder,convlstm,decoder, head):
                super(Network, self).__init__()
                self.initializer = initializer
                self.encoder = encoder
                self.decoder = decoder
                self.head = head
                self.convlstm = convlstm
       
                #self.convlstms = nn.ModuleList([ConvLSTMCell(input_size = 512, hidden_size = 512, height=9, width=15) for i in range(num_layers)])
        
        def forward(self, images, masks = None):

            
            logits = []
            if images.dim()!=5:
                images = images.unsqueeze(0)

            c_original, feature_vector, c0,h0, logits_mask, cell_state_loss, hidden_state_loss = self.initializer(images)

    
            cell_states = []
            #logits.append(logit_mask)
            length = images.shape[1]
        
            # logits.append(logits_mask)
            loss = 0
            weights = [0.1, 0.25, 0.5, 0.25, 0.1]
            ce_weights = calculate_weights(masks)
            ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
            for i in range(3,length):
                
                image = images[:,i,:,:,:]
                x_tilda = self.encoder(image)

                feature_vector = x_tilda[5]

                h_next,c_next = self.convlstm(feature_vector, h0, c0)


                x_tilda[5] = h_next
                decoder_output = self.decoder(*x_tilda)

                c0 = c_next
                h0 = h_next
                
                
                logit = self.head(decoder_output)
                mask = masks[:,i,:,:]
                mask = mask.contiguous()
                lovasz = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logit, mask)
                criterion = nn.CrossEntropyLoss(weight = ce_weights, ignore_index=-1)
                ce_logit = criterion(logit, mask)
                loss = loss + (lovasz + ce_logit) * weights[i].clone()
                
                logits_mask = logits_mask.squeeze(0)
                logits.append(logits_mask)
                
            loss = loss + cell_state_loss
            logits = torch.stack(logits, dim=1).cuda()
            
            if logits.dim()!= 5:
                logits_mask.unsqueeze(0)
            
            logits = logits.transpose(2,1) #Â makes in the dimension of classes, no of images, width, height so 8,7,480,288
            # print(logits.shape)
            return loss, logits

class UnetInitialiser(nn.Module):
    def __init__(self, encoder,convlstm,decoder, head, sizes):
        super(UnetInitialiser, self).__init__()
        self.encoder = encoder
        self.convlstm = convlstm
        self.decoder = decoder
        self.head = head

       




    def forward(self, images, masks = None):

        
        
        image_0 = images[:,0,:,:,:]
        image_1 = images[:,1,:,:,:]
        image_2 = images[:,2,:,:,:]
        if masks!=None:
            mask = masks[:,2,:,:]
            mask = mask.contiguous().long()

        
        fv1 = self.encoder(image_0)
        fv2 = self.encoder(image_1)
        x_tilda = self.encoder(image_2)
        features = x_tilda.copy()
        

        cell_states = []
        hidden_states = []


        c0 = fv1[5]
        h0 = fv2[5]

        x_tilda = self.encoder(image_2)
        feature_vector = x_tilda[5]

        h_next,c_next = self.convlstm(feature_vector, h0, c0)
        x_tilda[5] = h_next
        decoder_output = self.decoder(*x_tilda)

        logits_mask = self.head(decoder_output)
        hidden_loss = nn.MSELoss()
        cell_loss = nn.MSELoss()


        hidden_state_loss = hidden_loss(h_next, h0)
        cell_state_loss = cell_loss(c_next, c0)

        if masks==None:
            return c0, feature_vector, c_next,h_next, logits_mask, cell_state_loss, hidden_state_loss
      
        # loss calculation 
        lovasz_loss = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logits_mask, mask)
        
        ce_weights = calculate_weights(masks)
        ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
        criterion = nn.CrossEntropyLoss(weight = ce_weights, ignore_index=-1)
        cross_entropy_loss = criterion(logits_mask, mask)

        


        loss = (lovasz_loss + cross_entropy_loss + (cell_state_loss + hidden_state_loss))

    
        return c_next,h_next, logits_mask
    
def train_function(data_loader, model, optimizer):
    
    model.train()
    total_loss = 0.0
    
    for images, masks in tqdm(data_loader):
        
        images = images.to(device = DEVICE)
        masks = masks.to(device = DEVICE, dtype=torch.long)

        
        optimizer.zero_grad()
        # logits, cell_state_loss, hidden_state_loss = model(images, masks)
        # ce_weights = calculate_weights(masks)
        # ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
        # loss = 0
        # weights = [0.1, 0.25, 0.5, 0.25, 0.1]
        # count = 0
        loss, logits= model(images, masks)
        loss_sum = 0
        

        
        
        loss.backward()
        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)

        optimizer.step()
        total_loss += loss.item()
        # total_loss += loss_sum.item()

    return total_loss / len(data_loader)

def eval_function(data_loader, model):
    model.eval()
    total_loss = 0.0
    
    with torch.no_grad():
        for images, masks in tqdm(data_loader):
            images = images.to(device = DEVICE)
            masks = masks.to(device = DEVICE, dtype=torch.long)
            # logits, cell_state_loss, hidden_state_loss = model(images, masks)
            # ce_weights = calculate_weights(masks)
            # ce_weights = torch.tensor(ce_weights,dtype=torch.float).to(DEVICE)
            # loss = 0
            # count = 0
            # weights = [0.1, 0.25, 0.5, 0.25, 0.1]
            #weights = [0.5,0.6,0.7,0.8,2.0]
            loss, logits= model(images, masks)
            # for loss in losses:
            #     # optimizer.zero_grad()
            #     # loss.backward()
            #     # optimizer.step()
            #     loss_sum += loss


            total_loss += loss.item()
            # total_loss += loss_sum.item()

    return total_loss / len(data_loader)
    
sizes = [64,128,256,512]
# convlstm  = ConvLSTMCell(input_size = 512, hidden_size = 512)
# initialiser = UnetInitialiser(encoder,convlstm,decoder,head, sizes=sizes)


initialiser = ConvLSTM(512, 512, 2, encoder, decoder, head)

initialiser = initialiser.to(device = DEVICE)

initialiser.load_state_dict(torch.load(f'{DATA_URL}Models/U-net/2layers_3kernels.pt'))
checkpoint = torch.load(f'{DATA_URL}Models/kernel.pt')
initialiser.load_state_dict(checkpoint['model_state_dict'])
# model = SegmentationModel()
# model_summary = model.show()
# encoder = model_summary.encoder
# decoder = model_summary.decoder
# convlstm  = ConvLSTMCell(input_size = 512, hidden_size = 512)
# head = model_summary.segmentation_head

# initialiser2 = UnetInitialiser(encoder,convlstm,decoder,head, sizes=sizes)
# initialiser2.load_state_dict(torch.load(f'{DATA_URL}Models/U-net/initialiser_3frames_corrected_exp.pt'))

# encoder = initialiser.encoder
# decoder = initialiser.decoder
# convlstm = initialiser.convlstm
# head = initialiser.head

# convlstm  = ConvLSTMCell(input_size = 512, hidden_size = 512)

# new_model = Network(initialiser, encoder,convlstm,decoder, head)
# new_model = new_model.to(device = DEVICE)

# encoder = new_model.encoder 
# decoder = new_model.decoder


# for name,param in initialiser.named_parameters():
#    param.requires_grad = False


# for name,param in encoder.named_parameters():
#    param.requires_grad = False
#    if ".layer4" in name:
#         param.requires_grad = True



# for name,param in decoder.named_parameters():
#    param.requires_grad = False
#    if ".layer4" in name:
#         param.requires_grad = True

# for name,param in head.named_parameters():
#   param.requires_grad = True

for name,param in initialiser.named_parameters():
    logger.info(f"{name}, {param.requires_grad}")

epoch_start = 0

best_valid_loss = np.inf

EPOCHS = 100


valid_losses = []
train_losses = []



LR = 1e-6
# optimizer = torch.optim.SGD(initialiser.parameters(), lr=LR, momentum=0.9)
optimizer = torch.optim.Adam(initialiser.parameters(), lr = LR)

# optimizer = torch.optim.Adam(
#     [
#         {"params": new_model.initializer.encoder.parameters(), "lr": 1e-6},
#         {"params": new_model.initializer.decoder.parameters(), "lr": 1e-6},
#         {"params": new_model.initializer.head.parameters(), "lr": 1e-6},
#         {"params": new_model.initializer.convlstm.parameters(), "lr": 1e-8},
#     ],
#     lr=5e-4,
# )
# lambda1 = lambda1 = lambda epoch : pow((1 - epoch / EPOCHS), 0.9)
# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lambda1)

scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)
number_epoch_to_save = 5
 
counter = 0

print(epoch_start, best_valid_loss)
NUM_ACCUMULATION_STEPS = 4

gradient_count = 0
for epoch in range(epoch_start,EPOCHS):
    gradient_count+=1

    train_loss = train_function(trainloader, initialiser, optimizer)
    valid_loss = eval_function(validloader, initialiser)

    # if ((gradient_count) % NUM_ACCUMULATION_STEPS == 0):
    #     optimizer.step()

  
  
    if valid_loss < best_valid_loss: #if best valid loss then upate new model
        torch.save(initialiser.state_dict(), f'{DATA_URL}Models/2layers_finetuned_3kernels.pt')
        print("Saved model")
        logger.info(f"Saved model: {valid_loss} - {epoch}") 
        best_valid_loss = valid_loss
        counter = 0

    scheduler.step()

    if counter > 20:
        print(f"Early stopping: {epoch}, best valid loss : {best_valid_loss}")
        logger.info(f"Early stopping") 
        break
    
    
        


    torch.save({
                'epoch': epoch,
                'model_state_dict': initialiser.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': valid_loss,
                'best_loss': best_valid_loss,
                'train_loss': train_loss,
                'train_losses': train_losses,
                'valid_losses': valid_losses
                }, f'{DATA_URL}Models/continue1.pt')

    #   #lrs.append(scheduler.get_last_lr())

    print(f"Epoch : {epoch+1} Train_loss : {train_loss} Valid_loss : {valid_loss} Learning rate: ")
    logger.info(f"Epoch : {epoch+1} Train_loss : {train_loss} Valid_loss : {valid_loss} Learning rate: ") 
    counter +=1
    np.savez('losses.npz', train=train_losses, valid=valid_losses)







