{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zggv6oZrOE38",
        "outputId": "9bd5966a-36ce-45d1-fee2-b08391b2cf59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (8.4.0)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m760.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.15.1+cu118)\n",
            "Collecting timm==0.6.12\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0+cu118)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (16.0.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16444 sha256=58bb615e122c77c58c7b3d1907751919c7c5b4f5e75b81cd95272f2c31ef329d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/16/24/752e89d88d333af39a288421e64d613b5f652918e39ef1f8e3\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=7d77bedf6d0d822b01ce668086744720d7ddd24b3163fe89b1f83cd5074b47b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/3b/4e/2f3015f1ab76f34be28e04c4bcee27e8cabfa70d2eadf8bc3b\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, huggingface-hub, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.13.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.2 timm-0.6.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-96t2id4h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-96t2id4h\n",
            "  Resolved https://github.com/albumentations-team/albumentations to commit b773a1aa69f9c823c7f593205614d05d32c039cb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (23.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (8.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2023.3.21)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.1.1)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.3.0-py3-none-any.whl size=125709 sha256=fe681298f9a6dd5d968922bc5f351535bfb31eaa81942ee80b5cd3de2561dd72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xxr_woqr/wheels/6d/72/93/d30af2a1f90e7c7e811e8fa43aa723971c91af45052ffa1b5a\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "Successfully installed albumentations-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpehNbQyOIWz",
        "outputId": "cf207fb1-97fb-489a-bc07-c9d3a903322f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-PclEhQOKn1"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import cv2\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os \n",
        "import copy\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl7-9OIeORBY"
      },
      "outputs": [],
      "source": [
        "CSV_FILE = '/content/Human-Segmentation-Dataset-master/train.csv' \n",
        "#says what picture corresponds to which mask\n",
        "DATA_DIR = '/content/'\n",
        "# where our data is stored\n",
        "\n",
        "DEVICE = 'cuda' #Cuda as using GPU\n",
        "\n",
        "EPOCHS = 50 #25 training iterations\n",
        "LR = 0.001 #decay learning rate\n",
        "IMAGE_SIZE = 320\n",
        "HEIGHT = 288\n",
        "WIDTH = 480\n",
        "BATCH_SIZE = 4\n",
        "NO_OF_IMAGES = 100\n",
        "# Images are irregular shape so need to resize\n",
        "\n",
        "ENCODER = 'resnet34' \n",
        "WEIGHTS = 'imagenet' #use weights from imagenet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "dULHzNfCOTho",
        "outputId": "556e02b7-b39d-4039-b434-7c2c74b1080c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pictures 3391\n",
            "Number of pictures 3391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               masks  \\\n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "\n",
              "                                              images  \n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e26dbcea-c918-49b3-983c-f90b8ea94338\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masks</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e26dbcea-c918-49b3-983c-f90b8ea94338')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e26dbcea-c918-49b3-983c-f90b8ea94338 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e26dbcea-c918-49b3-983c-f90b8ea94338');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os \n",
        "import copy\n",
        "import glob\n",
        "training_masks = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Training/8_Annotations/*.png\"))\n",
        "print(\"Number of pictures {}\".format(len(training_masks)))\n",
        "\n",
        "\n",
        "training_images = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Training/Images/*.png\"))\n",
        "print(\"Number of pictures {}\".format(len(training_images)))\n",
        "\n",
        "\n",
        "dict_images = {'masks' : training_masks, 'images' :training_images}\n",
        "\n",
        "train_df = pd.DataFrame(dict_images)\n",
        "train_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob.glob(f\"/content/drive/MyDrive/Dissertation/Augmented_images/images_17/*.png\")\n",
        "masks = glob.glob(f\"/content/drive/MyDrive/Dissertation/Augmented_images/masks_17/*.png\")\n",
        "\n",
        "dict_images = {'masks' : masks, 'images' :images}\n",
        "aug_images = pd.DataFrame(dict_images)\n",
        "\n",
        "# train_df = pd.concat([train_df, aug_images], ignore_index=True)\n",
        "# print(len(train_df))"
      ],
      "metadata": {
        "id": "RtRnajQuOXDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_images.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KJxIDSx9VLSK",
        "outputId": "489c5490-cbf3-4391-cb94-068c0fb7ef4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               masks  \\\n",
              "0  /content/drive/MyDrive/Dissertation/Augmented_...   \n",
              "1  /content/drive/MyDrive/Dissertation/Augmented_...   \n",
              "2  /content/drive/MyDrive/Dissertation/Augmented_...   \n",
              "3  /content/drive/MyDrive/Dissertation/Augmented_...   \n",
              "4  /content/drive/MyDrive/Dissertation/Augmented_...   \n",
              "\n",
              "                                              images  \n",
              "0  /content/drive/MyDrive/Dissertation/Augmented_...  \n",
              "1  /content/drive/MyDrive/Dissertation/Augmented_...  \n",
              "2  /content/drive/MyDrive/Dissertation/Augmented_...  \n",
              "3  /content/drive/MyDrive/Dissertation/Augmented_...  \n",
              "4  /content/drive/MyDrive/Dissertation/Augmented_...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47e2f869-388c-474b-a0b0-e30b60ea9ab5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masks</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/Augmented_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47e2f869-388c-474b-a0b0-e30b60ea9ab5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47e2f869-388c-474b-a0b0-e30b60ea9ab5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47e2f869-388c-474b-a0b0-e30b60ea9ab5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(aug_images.masks)\n",
        "augmented_images = []\n",
        "for image_path in aug_images.masks:\n",
        "    path, file = os.path.split(image_path)\n",
        "    file = file.replace(\".png\", \"\")\n",
        "    augmented_images.append(f\"/cs/student/projects1/2019/nsultana/new_data/Training1/{file}.npz\")"
      ],
      "metadata": {
        "id": "BG3jPlq_VYTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRnYhWTpWgJM",
        "outputId": "3e419807-16fd-4b12-d6a3-2b6e331cb3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame005810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame007010.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame007020.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame011330.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame016070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame017160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame017260.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame017380.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020090.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020110.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020120.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020130.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020140.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020170.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020180.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020210.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020240.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020260.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020280.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020290.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame020310.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame022220.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video10_frame022260.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame006770.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame006830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame006880.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame008360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame008420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011280.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011290.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011310.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011320.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011330.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011340.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011350.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011370.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011380.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011600.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame011820.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012140.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012200.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012400.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video11_frame012550.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame002930.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame003450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame006350.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame006540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame006610.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame006730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010680.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010700.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame010720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame012050.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame012160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame012190.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video13_frame012810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame001290.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame001300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame001500.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame001510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame001830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame002280.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame008780.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame009150.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame009160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame009210.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame009350.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame010460.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame010820.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014840.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014850.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014860.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014900.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014910.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014930.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014940.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014950.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014970.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame014990.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015000.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015010.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015020.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015050.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015060.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video14_frame015070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame005530.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame005580.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008320.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008470.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008490.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame008630.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame009360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011020.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011030.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011040.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011050.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011060.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011080.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011090.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011100.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011110.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011120.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame011870.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video15_frame012070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame006720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame007190.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009660.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009680.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009700.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009740.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009750.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame009760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame010050.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video17_frame010320.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006500.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006560.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006610.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame006620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009770.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009850.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009860.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009880.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009910.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video18_frame009920.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame014720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame014820.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame019760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame059230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame059270.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060190.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060310.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video19_frame060420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame000430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame000440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame000460.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame000470.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009460.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009530.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009550.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009570.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009580.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame009590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame010880.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame011400.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame011450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video1_frame012610.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame004450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame004890.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005210.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005520.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005770.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005840.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005850.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame005970.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006010.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006120.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006220.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006240.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006750.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006860.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006980.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame006990.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame007180.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame008070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame008560.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame008590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame008650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame008680.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame013410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame013420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame013430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame013440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame013450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame014020.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame014400.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame014620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame014760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame014870.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame015000.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame015090.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video20_frame015270.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003030.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003050.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003610.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003630.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003890.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame003910.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004200.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004750.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame004840.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame005010.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame005430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame005560.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006290.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006660.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame006700.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007120.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007290.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007460.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007500.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007680.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame007730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009740.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009750.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009770.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009780.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009790.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009800.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame009820.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame013550.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video21_frame014650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame002690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame002700.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008680.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008700.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008740.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008750.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame008760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame009400.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame009620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame009710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video23_frame009760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame005410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013460.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013470.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013480.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013490.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013500.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013520.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013530.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013550.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013560.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013570.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013860.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame013940.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014010.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014040.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014120.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014170.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014480.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014490.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video24_frame014620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame001900.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame003650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame005220.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame006180.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame006440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame006730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame006960.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame009190.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame009300.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame009340.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame010220.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011200.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011220.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011250.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011260.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011310.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011330.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011340.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011350.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011360.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011370.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame011480.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video3_frame016170.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame004830.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame007240.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame009520.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame009580.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame009590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame009600.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame012410.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame012420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame012440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video4_frame012450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame000160.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame000170.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame000180.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame001880.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame002390.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame002850.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame003080.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame003350.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame003420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame003500.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame003760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame004270.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame004340.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame004370.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame004440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame004540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame006190.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame012100.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video6_frame012310.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame000420.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame000430.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame000440.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame000990.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame001710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame002670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame003030.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame006690.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame010230.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame010330.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame010370.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame010520.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017490.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017510.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017520.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017570.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017610.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017630.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017640.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017660.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame017670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame022330.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video8_frame025980.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame004070.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame004730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame004890.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame004930.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame007210.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame007490.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame007800.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame007810.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010450.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010470.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010540.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010580.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010590.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010600.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010620.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010650.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010660.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010670.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010720.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010730.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010760.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame010770.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame012100.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame014710.npz', '/cs/student/projects1/2019/nsultana/new_data/Training/Video9_frame014730.npz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed(f\"aug_images.npz\", images=augmented_images)"
      ],
      "metadata": {
        "id": "LFlP_kdMWEt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "-EmPHrMKOUsP",
        "outputId": "61fa6bf2-ccd6-4d64-c3f6-7b2f919966e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pictures 534\n",
            "Number of pictures 534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               masks  \\\n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/V...   \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/V...   \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/V...   \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/V...   \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/V...   \n",
              "\n",
              "                                              images  \n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/V...  \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/V...  \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/V...  \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/V...  \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/V...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cb0443a-01b2-4e39-8e31-7d848181eb2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masks</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cb0443a-01b2-4e39-8e31-7d848181eb2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cb0443a-01b2-4e39-8e31-7d848181eb2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cb0443a-01b2-4e39-8e31-7d848181eb2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "validation_masks = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Validation/8_Annotations/*.png\"))\n",
        "\n",
        "print(\"Number of pictures {}\".format(len(validation_masks)))\n",
        "\n",
        "validation_images = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Validation/Images/*.png\"))\n",
        "\n",
        "print(\"Number of pictures {}\".format(len(validation_images)))\n",
        "\n",
        "dict_images = {'masks' : validation_masks, 'images' :validation_images}\n",
        "\n",
        "valid_df = pd.DataFrame(dict_images)\n",
        "\n",
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "1jsrfTUzOYXz",
        "outputId": "f72aaf51-78f3-42a5-a56b-c68283024baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pictures 586\n",
            "Number of pictures 586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               masks  \\\n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/T...   \n",
              "\n",
              "                                              images  \n",
              "0  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "1  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "2  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "3  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  \n",
              "4  /content/drive/MyDrive/Dissertation/VGG_UNet/T...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ef9ce50-8841-4286-8396-0f327f8191b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masks</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "      <td>/content/drive/MyDrive/Dissertation/VGG_UNet/T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ef9ce50-8841-4286-8396-0f327f8191b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ef9ce50-8841-4286-8396-0f327f8191b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ef9ce50-8841-4286-8396-0f327f8191b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "testing_masks = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Testing/8_Annotations/*.png\"))\n",
        "\n",
        "print(\"Number of pictures {}\".format(len(testing_masks)))\n",
        "\n",
        "testing_images = sorted(glob.glob(f\"/content/drive/MyDrive/Dissertation/VGG_UNet/Testing/Images/*.png\"))\n",
        "\n",
        "print(\"Number of pictures {}\".format(len(testing_images)))\n",
        "\n",
        "dict_images = {'masks' : testing_masks, 'images' :testing_images}\n",
        "\n",
        "test_df = pd.DataFrame(dict_images)\n",
        "\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kEDlzP9OdW4"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "valid_df = valid_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FOoSpM5lE1G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"training.csv\")\n",
        "valid_df.to_csv(\"validation.csv\")\n",
        "test_df.to_csv(\"testing.csv\")"
      ],
      "metadata": {
        "id": "YbLMmasEE17E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mh0X5_4hVyFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"training.csv\")\n",
        "valid_df= pd.read_csv(\"validation.csv\")\n",
        "test_df =pd.read_csv(\"testing.csv\")"
      ],
      "metadata": {
        "id": "fVNu_9Qz_TYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"training (1).csv\")"
      ],
      "metadata": {
        "id": "pvbRgEM8ZUsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz5qvjdyOo9c"
      },
      "outputs": [],
      "source": [
        "def generateMasks(predicted_flows, next, real_mask):\n",
        "  \n",
        "  dim = (WIDTH, HEIGHT)\n",
        "  first= True\n",
        "  masks = []\n",
        "\n",
        "  for flow in predicted_flows:\n",
        "    \n",
        "    flow = flow.detach().to('cpu').numpy()\n",
        "    flow = np.moveaxis(flow, 0, -1)\n",
        "    if next:\n",
        "      flow = -flow\n",
        "\n",
        "    h = flow.shape[0]\n",
        "    w = flow.shape[1]\n",
        "    \n",
        "    flow[:,:,0] += np.arange(w)\n",
        "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
        "\n",
        "    if first:\n",
        "      \n",
        "      mask = real_mask\n",
        "      \n",
        "      mask = mask[:,:,np.newaxis]\n",
        "      \n",
        "      if next: \n",
        "        frame = np.squeeze(mask, axis=(-1,))\n",
        "        \n",
        "        temp = frame\n",
        "        temp[temp == 8] = 0\n",
        "        frame = torch.Tensor(frame)\n",
        "        temp = torch.Tensor(temp)\n",
        "        real_mask = frame\n",
        "        masks.append(temp) \n",
        "\n",
        "      \n",
        "      new_frame = cv2.remap(mask, flow, None, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT,  borderValue=100)\n",
        "      first=False\n",
        "\n",
        "    else:\n",
        "      \n",
        "      new_frame = cv2.remap(new_frame, flow, None, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=100 )\n",
        "\n",
        "    frame = torch.Tensor(new_frame) \n",
        "            \n",
        "    frame = frame_processing(frame)\n",
        "    frame = torch.Tensor(frame)\n",
        "    masks.append(frame)\n",
        "  return masks\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frame_processing(mask):\n",
        "  mask[mask == 100] = -1\n",
        "  temp_mask = np.copy(mask)\n",
        "  temp_mask[temp_mask !=7] = 50\n",
        "\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(4,4))\n",
        "  res = cv2.morphologyEx(temp_mask,cv2.MORPH_OPEN,kernel, iterations=1)\n",
        "  res[res == 50] = 0\n",
        "  instrument_mask = ma.make_mask(res)\n",
        "  filled_mask = np.copy(mask)\n",
        "  filled_mask[instrument_mask] = 0\n",
        "  result = (res + filled_mask)\n",
        "  return result"
      ],
      "metadata": {
        "id": "0ZbGmxyLseRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9lMjY9_OrvY"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.optical_flow import Raft_Small_Weights, Raft_Large_Weights\n",
        "from torchvision.models.optical_flow import raft_small, raft_large\n",
        "\n",
        "def getMaskSequence(images, real_mask):\n",
        "  weights = Raft_Large_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model = raft_large(weights=Raft_Large_Weights.DEFAULT, progress=False).to('cuda')\n",
        "    model = model.eval()\n",
        "\n",
        "  masks = []\n",
        "  for i in range (0,2):\n",
        "    if i==0:\n",
        "      # img1_batch = torch.stack(list(images[0:3])[::-1])\n",
        "      # img2_batch = torch.stack(list(images[1:4])[::-1])\n",
        "      img1_batch = torch.stack(list(images[0:7])[::-1])\n",
        "      img2_batch = torch.stack(list(images[1:8])[::-1])\n",
        "      # \n",
        "    else:\n",
        "      # img1_batch = torch.stack(list(images[3:6]))\n",
        "      # img2_batch = torch.stack(list(images[4:7]))\n",
        "      img1_batch = torch.stack(list(images[7:10]))\n",
        "      img2_batch = torch.stack(list(images[8:11]))\n",
        "    \n",
        "    img1_batch, img2_batch = transforms(img1_batch, img2_batch)\n",
        "    with torch.no_grad():\n",
        "      list_of_flows = model(img1_batch.to('cuda'), img2_batch.to('cuda'))\n",
        "    \n",
        "    predicted_flows = list_of_flows[-1]\n",
        "    if i==0:\n",
        "      new_masks = generateMasks(predicted_flows, False, real_mask)[::-1]\n",
        "    else:\n",
        "      new_masks = generateMasks(predicted_flows, True, real_mask)\n",
        "\n",
        "    masks += new_masks\n",
        "  maskData = torch.stack(masks)\n",
        "\n",
        "  return maskData \n",
        "\n",
        "#masks = getMaskSequence(images, mask_path)\n",
        "  \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNaDoHXhO07M"
      },
      "outputs": [],
      "source": [
        "\n",
        "def replaceNewPixels(real_mask, optical_flow):\n",
        "\n",
        "    real_mask_labels = np.unique(real_mask)\n",
        "    optical_flow_labels = np.unique(optical_flow)\n",
        "    main_list = np.setdiff1d(optical_flow_labels,real_mask_labels)\n",
        "   \n",
        "    for value in main_list:\n",
        "\n",
        "      optical_flow[optical_flow == value] = -1\n",
        "    \n",
        "    optical_flow[optical_flow == 8] = 0\n",
        "    \n",
        "    return optical_flow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for image_path in aug_images.images:\n",
        "  # path, file = os.path.split(image_path)\n",
        "  # if \"Augmented_images\" in path:\n",
        "  #   print(\"True\")\n",
        "  # file = file.replace(\".png\", \"\")\n",
        "  file_path, mask_path = getFilePath(image_path, \"Testing\")\n",
        "  print(file_path)"
      ],
      "metadata": {
        "id": "6l1g8jHc7aIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT--QRwnPUCT"
      },
      "outputs": [],
      "source": [
        "def createImageSequence(sequences):\n",
        "  images = []\n",
        "  dim = (960, 544)\n",
        "  #images = torch.Tensor(10, HEIGHT, WIDTH)\n",
        "  for image_path in sequences:\n",
        "    image = cv2.imread(image_path)\n",
        "    try:\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    except:\n",
        "      print(\"error\", image_path)\n",
        "      \n",
        "    \n",
        "    image = cv2.resize(image, dim)\n",
        "    image = image / 255.0\n",
        "    image = torch.Tensor(image) \n",
        "    image = image.permute(2, 0, 1)\n",
        "    images.append(image)\n",
        "\n",
        "  #images = torch.stack(images)\n",
        "  return images\n",
        "\n",
        "def getFilePath(image_path, split):\n",
        "  path, file = os.path.split(image_path)\n",
        "  file = file.replace(\".png\", \"\")\n",
        "  parts = file.split(\"_\")\n",
        "  video = parts[0]\n",
        "  frame = parts[1]\n",
        "\n",
        "  #/content/drive/MyDrive/Dissertation/frames/Video1/Video1_frame000090\n",
        "  file_path = f\"/content/drive/MyDrive/Dissertation/frames/{video}/{video}_{frame}/*.png\"\n",
        "  mask_path = f\"/content/drive/MyDrive/Dissertation/VGG_UNet/{split}/8_Annotations/{video}_{frame}.png\"\n",
        "\n",
        "  return file_path, mask_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WMVbTQMrMxr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "import numpy.ma as ma\n",
        "no_of_images = test_df.shape[0]\n",
        "aug = A.Compose([\n",
        "A.Resize(height=544, width=960)\n",
        "])\n",
        "\n",
        "\n",
        "dim = (WIDTH, HEIGHT)\n",
        "# mask_dim = (960, 544)\n",
        "for idx in range (0, no_of_images):\n",
        "    row = test_df.iloc[idx]\n",
        "    print( idx)\n",
        "    image_path = row.images\n",
        "    mask_path = row.masks\n",
        "    file_path, mask_path = getFilePath(image_path, \"Testing\")\n",
        "    \n",
        "    file_name = os.path.split(mask_path)[1].replace(\".png\", \"\")\n",
        "    \n",
        "    \n",
        "\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    sequences = sorted(glob.glob(file_path))\n",
        "    sequences = sequences[3:14]\n",
        "    try:\n",
        "      images = createImageSequence(sequences)\n",
        "      \n",
        "      temp_image = images[3].numpy().transpose(2, 1, 0)\n",
        "      \n",
        "      temp_image = cv2.resize(temp_image, mask_dim)\n",
        "      \n",
        "      aug_result = aug(image=temp_image,mask=mask)\n",
        "      #mask = cv2.resize(mask, dim, cv2.INTER_NEAREST)\n",
        "      resized_mask = aug_result['mask']\n",
        "      #resized_mask[resized_mask == 0] = 8\n",
        "      masks = getMaskSequence(images, resized_mask)\n",
        "      masks = masks.numpy()\n",
        "      \n",
        "      images = np.stack(images, axis=0)\n",
        "\n",
        "\n",
        "      #np.savez_compressed(f\"/content/drive/MyDrive/Testing/{file_name}\", images=images, masks=masks)\n",
        "      \n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vFa0prtnpsf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}