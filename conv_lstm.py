# -*- coding: utf-8 -*-
"""conv lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pk_9y1txgv_KprxWLG0C-PkaUjAF-E3J

# Installation
"""

import torch 
import cv2

import numpy as np 
#import pandas as pd
import matplotlib.pyplot as plt 

from tqdm import tqdm

import os 
import copy
import glob
from torch import nn # neural netowrk 
import timm

import segmentation_models_pytorch as smp
from segmentation_models_pytorch.losses import DiceLoss, LovaszLoss, FocalLoss, JaccardLoss

from math import log

from torch import optim
import torchvision.models as models
import torch.nn.functional as f

DEVICE = torch.device('cuda') 
# DEVICE = 'cuda' #Cuda as using GPU


print(torch.cuda.device_count())
print(torch.cuda.get_device_name())
EPOCHS = 50 #25 training iterations
LR = 0.00001 #decay learning rate
BATCH_SIZE = 4
HEIGHT = 288
WIDTH = 480
ENCODER = 'resnet34'
WEIGHTS = 'imagenet'
DATA_URL = "/cs/student/projects1/2019/nsultana/"

import random
training_images = (glob.glob(f"{DATA_URL}Data/Training/*.npz"))

# # training_images = training_images[:100]

testing_images = (glob.glob(f"{DATA_URL}Data/Testing/*.npz"))

validation_images = (glob.glob(f"{DATA_URL}Data/Validation/*.npz"))
print(len(validation_images))

# validation_images = validation_images[:100]

"""# Set up model"""

import albumentations as A
from albumentations.pytorch import ToTensorV2
print(torch.version.cuda)
class SegmentationModel(nn.Module):

  def __init__(self):
    super(SegmentationModel, self).__init__() 

    self.architecture = smp.Unet(
        encoder_name = ENCODER,
        encoder_weights = WEIGHTS, 
        in_channels = 3, #Input is RGB
        classes = 8, # binary segmentation problem 
        activation = None #no sigmoid or softmax

    )
  
  def show(self):
    return self.architecture

  def forward(self, images, masks = None):
    logits = self.architecture(images) #probabilities / predictions
   
    
    if masks!= None:
      weights = [4.116647326424263, 24.600245093614593, 191.78790779880697, 240.94195047235274, 7.334747505863925, 10.620043927212807, 2.219872768361696, 38.32265526553685]

      class_weights=torch.tensor(weights,dtype=torch.float).to(DEVICE)
      lovasz = LovaszLoss(mode = 'multiclass')(logits, masks)
      #loss_fn = nn.CrossEntropyLoss()#binary cross entropy loss

      loss = lovasz
      return logits, loss

    return logits

model = SegmentationModel()
model = model.to(device =DEVICE); #i.e CUDA



class Initializer(nn.Module):
	def __init__(self):
		super(Initializer, self).__init__()
		self.new_layer = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=3)
		

		self.pretrained_model = models.vgg16(pretrained=True)
		self.model = nn.Sequential(*list(self.pretrained_model.features.children())[2:31])
		self.interp = nn.functional.interpolate

		self.c0 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1)
		

		self.h0 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1)
		
		self.relu = nn.ReLU()

	def forward(self, inputs):
		x = self.relu(self.new_layer(inputs))
		x = self.model(x)
		c0 = self.relu(self.c0(x))
		h0 = self.relu(self.h0(x))
		c0 = self.interp(c0, size=(9,15), mode='bilinear', align_corners=False)
		h0 = self.interp(h0, size=(9,15), mode='bilinear', align_corners=False)
		return c0,h0

class ConvLSTMCell(nn.Module):
    """
    Generate a convolutional LSTM cell
    """

    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.conv = nn.Conv2d(input_size + hidden_size, 4 * hidden_size, 3, padding=3 // 2)

    def forward(self, input_, hiddenState, cellState):
        

        prev_hidden = hiddenState
        prev_cell = cellState

        # data size is [batch, channel, height, width]
        stacked_inputs = torch.cat((input_, prev_hidden), 1)
        combined_conv = self.conv(stacked_inputs)

        # chunk across channel dimension -> get conv inputs
        in_gate, remember_gate, out_gate, cell_gate = combined_conv.chunk(4, 1)

        # apply sigmoid non linearity 
        in_gate = torch.sigmoid(in_gate)
        remember_gate = torch.sigmoid(remember_gate)
        out_gate = torch.sigmoid(out_gate)

        # apply tanh non linearity instead of sigmoid
        cell_gate = f.relu(cell_gate)

        # compute current cell and hidden state
        cell = (remember_gate * prev_cell) + (in_gate * cell_gate)
        hidden = out_gate * f.relu(cell)

        return hidden, cell

class LSTMModel(nn.Module):
    def __init__(self, initializer, encoder,convlstm,decoder, head):
        super(LSTMModel, self).__init__()
        self.initializer = initializer
        self.encoder = encoder
        self.convlstm = convlstm
        self.decoder = decoder
        self.head = head
    
    def getInitializer(self):
      return self.initializer

    def getLSTM(self):
      return self.convlstm
    
    def getEncoder(self):
      return self.encoder

    def getDecoder(self):
      return self.decoder

    def forward(self, images, mask):
      logits = []
      
      first_image = images[0]
      first_image = first_image.to(DEVICE).unsqueeze(0)
      
      mask = mask.to(device = DEVICE).unsqueeze(0)
      mask = mask.unsqueeze(0)
      #mask = np.swapaxes(mask,1,2)

   

      c0,h0 = self.initializer(torch.cat((first_image,mask),1))

      for i in range(1,len(images)):
        image = images[i,:,:,:]
        image = image.to(device = DEVICE).unsqueeze(0)

        x_tilda = self.encoder(image)
        features = x_tilda
        feature_vector = x_tilda[5]
        c_next,h_next = self.convlstm(feature_vector, h0, c0)
        decoder = self.decoder

        features[5] = h_next
        decoder_output = decoder(*features)
        c0 = c_next
        h0 = h_next
        
        logits_mask = self.head(decoder_output)
        logits_mask = logits_mask.squeeze(0)
        logits.append(logits_mask)
        
      logits = torch.stack(logits)

      logits = logits.transpose(1,0) #Â makes in the dimension of classes, no of images, width, height so 8,7,480,288
      
      return logits

# """# Set up dataset and data loader"""

# # increases more images for training dataset


def get_train_augs():
  return A.Compose([
      A.RandomCrop(height=192, width=320, p=0.2),
      A.Resize(height = HEIGHT, width = WIDTH),
      A.HorizontalFlip(p = 0.5),
      A.VerticalFlip(p = 0.5),
      A.GaussianBlur(blur_limit=3, p=0.5),
      A.ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),
      ToTensorV2(),

      
      
  ], additional_targets={'image1': 'image', 'image2': 'image', 'image3': 'image', 'image4': 'image', 'image5': 'image', 'image6': 'image'
  ,'mask1': 'mask', 'mask2': 'mask', 'mask3': 'mask', 'mask4': 'mask', 'mask5': 'mask', 'mask6': 'mask' })


# for validation and test set
def get_valid_augs():
  return A.Compose([
      
      ToTensorV2()
      
  ], additional_targets={'image1': 'image', 'image2': 'image', 'image3': 'image', 'image4': 'image', 'image5': 'image', 'image6': 'image'
  ,'mask1': 'mask', 'mask2': 'mask', 'mask3': 'mask', 'mask4': 'mask', 'mask5': 'mask', 'mask6': 'mask' })

def get_test_augs():
  return A.Compose([
      
      ToTensorV2()
      
  ], additional_targets={'image1': 'image', 'image2': 'image', 'image3': 'image', 'image4': 'image', 'image5': 'image', 'image6': 'image'
  ,'mask1': 'mask', 'mask2': 'mask', 'mask3': 'mask', 'mask4': 'mask', 'mask5': 'mask', 'mask6': 'mask' })

from torch.utils.data import Dataset


class SegmentationDataset(Dataset):

  def __init__(self, split, augmentations, sequence):
   # self.df = df
    self.split = split
    self.augmentations = augmentations
    self.sequence = sequence
  
  def __len__(self):
    return len(self.sequence)
  

  def __getitem__(self, idx):
    # image_name = self.sequence[idx]
    # images, masks = generateImagesMasks(image_name, self.split)
    path = self.sequence[idx]
    array = np.load(path)
    
    images = array['images']
    masks = array['masks']
    
    #print(set(masks[0].flatten()))

    images = np.transpose(images, (0, 2,3,1))
    transformed_images = []
    transformed_masks = []

    
   

    if self.augmentations:
      data = self.augmentations(image=images[0],image1=images[1],image2=images[2],image3=images[3],image4=images[4],image5=images[5],
                                image6=images[6], mask=masks[0], mask1=masks[1], mask2=masks[2], mask3=masks[3], mask4=masks[4], mask5=masks[5],mask6=masks[6])
     
      

      transformed_images.append(data['image'])
      transformed_images.append(data['image1'])
      transformed_images.append(data['image2'])
      transformed_images.append(data['image3'])
      transformed_images.append(data['image4'])
      transformed_images.append(data['image5'])
      transformed_images.append(data['image6'])

      transformed_masks.append(data['mask'])
      transformed_masks.append(data['mask1'])
      transformed_masks.append(data['mask2'])
      transformed_masks.append(data['mask3'])
      transformed_masks.append(data['mask4'])
      transformed_masks.append(data['mask5'])
      transformed_masks.append(data['mask6'])
      
      
      transformed_images = torch.stack(transformed_images)
      transformed_masks = torch.stack(transformed_masks)
      return transformed_images, transformed_masks
    
    
    # masks = getMaskSequence(transformed_images, mask)


    return images, masks

trainset = SegmentationDataset("Training", get_train_augs(), training_images)
validset = SegmentationDataset("Validation", get_valid_augs(), validation_images)
testset = SegmentationDataset("Testing", get_test_augs(), testing_images)

from torch.utils.data import DataLoader
trainloader = DataLoader(trainset, batch_size = 4, shuffle = True,num_workers=2) #every epoch batches shuffles
validloader = DataLoader(validset, batch_size = 4, shuffle = True,num_workers=2)

# images, masks = trainset[1]
# for mask in masks:
#     mask[mask !=0] = 100
#     print(np.unique(mask))
#     plt.imshow(mask)
#     plt.show()
"""# Set up training and validation"""
print(torch.cuda.current_device())
from torch.autograd import Variable
from numpy.lib.stride_tricks import sliding_window_view

def train_function(data_loader, model, optimizer):

  model.train()
  total_loss = 0.0

  for images, masks in tqdm(data_loader):

    images = images.to(device = DEVICE)
    masks = masks.to(device = DEVICE, dtype=torch.long)
    
    
    # make sure gradients are 0
    optimizer.zero_grad()
    logits = []
    triplet_sequences = []
    for i in range (0, len(images)):
      mask = masks[i][0]
      logits_mask = model(images[i], mask)
      logits.append(logits_mask)
      triplet_sequences.append(logits_mask.flatten())
        
    logits = torch.stack(logits)
    triplet_sequences = torch.stack(triplet_sequences)

    losses = []
    loss = 0
    count = 0
   
    weights =  [0.5, 0.7, 1.0, 0.7, 0.5, 0.1]



    
    # logit shape is  4,8,6,288,480
    
    for i in range (0, 6):

      logit = logits[:,:,i,:,:] #iterate per frame
      mask = masks[:,i,:,:]
      mask = mask.contiguous()
      loss_per_frame = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logit, mask)

      loss += loss_per_frame * weights[i]
      count+= weights[i]


    loss = loss / count
    

    # calculate triplet loss 
    
    array = np.array([0,1,2,3,4,5])
    arr = sliding_window_view(array, window_shape = 3)
    triplet_loss = nn.TripletMarginLoss(margin=0.0, p=2)
    output = 0
    
    for triplet in arr:
     
      anchor = logits[:,:,triplet[0],:, :].flatten()
      positive = logits[:,:,triplet[1],:, :].flatten()
      negative = logits[:,:,triplet[2],:, :].flatten()
      output += triplet_loss(anchor, positive, negative)
    
    output = output / len(arr)
    loss = loss + output  



    

    loss.backward() #backpropagation

    optimizer.step() #update weights

    total_loss += loss.item()

  return total_loss / len(data_loader)

def eval_function(data_loader, model):

  model.eval() 
  total_loss = 0.0

  with torch.no_grad():
    for images, masks in tqdm(data_loader):

      images = images.to(device = DEVICE)
      masks = masks.to(device = DEVICE, dtype=torch.long)
      logits = []
      for i in range (0, len(images)):
        mask = masks[i][0]
        logits.append(model(images[i], mask))
      logits = torch.stack(logits)
      losses = []
      loss = 0
      count = 0
      weights =  [0.5, 0.7, 1.0, 0.7, 0.5, 0.1]
    
      for i in range (0, 6):
        logit = logits[:,:,i,:,:] #iterate per frame
        mask = masks[:,i,:,:]
        mask = mask.contiguous()
        loss_per_frame = LovaszLoss(mode = 'multiclass', ignore_index=-1)(logit, mask)

        loss += loss_per_frame * weights[i]
        count+= weights[i]

      loss = loss / count
   
      # triplet loss
      array = np.array([0,1,2,3,4,5])
      arr = sliding_window_view(array, window_shape = 3)
      triplet_loss = nn.TripletMarginLoss(margin=0.0, p=2)
      output = 0
      
      for triplet in arr:
      
        anchor = logits[:,:,triplet[0],:, :].flatten()
        positive = logits[:,:,triplet[1],:, :].flatten()
        negative = logits[:,:,triplet[2],:, :].flatten()
        output += triplet_loss(anchor, positive, negative)
      
      output = output / len(arr)
      loss = loss + output  



      total_loss += loss.item()

  return total_loss / len(data_loader)

"""# Training model"""

model.load_state_dict(torch.load(f'{DATA_URL}Models/best_model_aug.pt'))
model_summary = model.show()
encoder = model_summary.encoder
initializer = Initializer()
decoder = model_summary.decoder
head = model_summary.segmentation_head

for name,param in encoder.named_parameters():
  param.requires_grad = False

for name,param in decoder.named_parameters():
  param.requires_grad = False

# for name,param in initializer.named_parameters():
#   param.requires_grad = False

convlstm  = ConvLSTMCell(input_size = 512, hidden_size = 512)
new_model = LSTMModel(initializer,encoder,convlstm,decoder, head)
new_model = new_model.to(device = DEVICE)

# initial = new_model.getInitializer()

# for name,param in initial.named_parameters():
#   print(param.requires_grad)

# #scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 0.00001, 0.001,5, cycle_momentum = False, mode='exp_range', gamma = 0.98)
# #lambda1 = lambda1 = lambda epoch : pow((1 - epoch / EPOCHS), 0.9)
# # #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lambda1) #polynomial
# #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95, last_epoch=- 1, verbose=False)


#new_model.load_state_dict(torch.load(f'{DATA_URL}Models/fine_tuned_2.pt'))

# checkpoint = torch.load(f'{DATA_URL}Models/conv_lstm_1_current.pt')
# new_model.load_state_dict(checkpoint['model_state_dict'])

# epoch_start = checkpoint['epoch']
# loss = checkpoint['loss']
# best_valid_loss = checkpoint['best_loss']
# training_loss = checkpoint['train_loss']

# EPOCHS = 50 - epoch_start
# #best_valid_loss = np.inf

# valid_losses = []
# train_losses = []

# lrs = []

# #0.12911548332047107 epoch 28 
# LR = 0.00001
# optimizer = torch.optim.Adam(new_model.parameters(), lr = LR)

# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# number_epoch_to_save = 5

# for epoch in range(0,EPOCHS):


#   train_loss = train_function(trainloader, new_model, optimizer)
#   valid_loss = eval_function(validloader, new_model)
#   train_losses.append(train_loss)
#   valid_losses.append(valid_loss)


#   if valid_loss < best_valid_loss: #if best valid loss then upate new model
#     torch.save(new_model.state_dict(), f'{DATA_URL}Models/conv_lstm_triplet_loss_continued.pt')
#     print("Saved model")
#     best_valid_loss = valid_loss

#   #scheduler.step()



#   if epoch % number_epoch_to_save == 0:

#     torch.save({
#               'epoch': epoch,
#               'model_state_dict': new_model.state_dict(),
#               'optimizer_state_dict': optimizer.state_dict(),
#               'loss': valid_loss,
#               'best_loss': best_valid_loss,
#               'train_loss': train_loss
#               }, f'{DATA_URL}Models/conv_lstm_1_current.pt')
  
# #   #lrs.append(scheduler.get_last_lr())
  
#   print(f"Epoch : {epoch+1} Train_loss : {train_loss} Valid_loss : {valid_loss} Learning rate:  ")

# """# Only training conv lstm and decoder + encoder"""



# encoder = new_model.getEncoder()
# decoder = new_model.getDecoder()

# for name,param in encoder.named_parameters():
#   print(param.requires_grad)
#   break

# new_model.load_state_dict(torch.load(f'{DATA_URL}Models/conv_lstm_triplet_loss.pt'))

# initializer = new_model.getInitializer()
# encoder = new_model.getEncoder()
# decoder = new_model.getDecoder()
# convlstm = new_model.getLSTM()
# for name,param in initializer.named_parameters():
#   param.requires_grad = False

# for name,param in convlstm.named_parameters():
#   param.requires_grad = True

# for name,param in encoder.named_parameters():
#   param.requires_grad = True

# for name,param in decoder.named_parameters():
#   param.requires_grad = True

# train_losses = []
# valid_losses = []
# # checkpoint = torch.load(f'{DATA_URL}Models/fine_tuned_current.pt')
# # new_model.load_state_dict(checkpoint['model_state_dict'])

# # epoch_start = checkpoint['epoch']
# # loss = checkpoint['loss']
# # best_valid_loss = checkpoint['best_loss']
# # training_loss = checkpoint['train_loss']

# LR = 0.00001
# optimizer = torch.optim.Adam(new_model.parameters(), lr = LR)

# # initializer = new_model.getInitializer()
# # encoder = new_model.getEncoder()
# # decoder = new_model.getDecoder()
# # convlstm = new_model.getLSTM()

# # for name,param in initializer.named_parameters():
# #   param.requires_grad = False

# # for name,param in convlstm.named_parameters():
# #   param.requires_grad = True

# # for name,param in encoder.named_parameters():
# #   param.requires_grad = True

# # for name,param in decoder.named_parameters():
# #   param.requires_grad = True

# # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# # # best_valid_loss = np.Inf

# EPOCHS = 50
# best_valid_loss = np.inf

# number_epoch_to_save = 5
# for epoch in range(0,EPOCHS):


#   train_loss = train_function(trainloader, new_model, optimizer)
#   valid_loss = eval_function(validloader, new_model)
#   train_losses.append(train_loss)
#   valid_losses.append(valid_loss)


#   if valid_loss < best_valid_loss: #if best valid loss then upate new model
#     torch.save(new_model.state_dict(), f'{DATA_URL}Models/fine_tuned_with_triplet_loss.pt')
#     print("Saved model")
#     best_valid_loss = valid_loss

#   #scheduler.step()



#   if epoch % number_epoch_to_save == 0:

#     torch.save({
#               'epoch': epoch,
#               'model_state_dict': new_model.state_dict(),
#               'optimizer_state_dict': optimizer.state_dict(),
#               'loss': valid_loss,
#               'best_loss': best_valid_loss,
#               'train_loss': train_loss
#               }, f'{DATA_URL}Models/fine_tuned_current.pt')
  
#   #lrs.append(scheduler.get_last_lr())
  
#   print(f"Epoch : {epoch+1} Train_loss : {train_loss} Valid_loss : {valid_loss} Learning rate:  ")

# checkpoint = torch.load('/content/drive/My Drive/Dissertation/conv_lstm_current_2.pt')
# new_model.load_state_dict(checkpoint['model_state_dict'])
# # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# # epoch_start = checkpoint['epoch']
# # loss = checkpoint['loss']
# # best_valid_loss = checkpoint['best_loss']
# # training_loss = checkpoint['train_loss']



# checkpoint = torch.load(f'{DATA_URL}Models/conv_lstm_1_current.pt')
# new_model.load_state_dict(checkpoint['model_state_dict'])
new_model.load_state_dict(torch.load(f'{DATA_URL}Models/conv_lstm_triplet_loss_continued.pt'))
# images, masks = testset[19]
# logits = new_model(images, masks)
# logits = logits.permute(1,0,2,3)
# predictions =  torch.nn.functional.softmax(logits[2], dim=0)
# pred_labels = torch.argmax(predictions, dim=0)

# # plt.imshow(pred_labels.cpu().detach().numpy())
# # plt.show()
# # plt.imshow(masks[3])
# # plt.show()

import sklearn.metrics as skm
def initialiseDictionary():
  labels = [0,1,2,3,4,5,6,7]
  label_stats = {}
  for label in labels:
    label_stats[label] = {'tp': 0, 'fn': 0, 'fp': 0}
  return label_stats


stats =initialiseDictionary()

labels = [0,1,2,3,4,5,6,7]


for idx in range (0, len(testset)):
  
  images, masks = testset[idx]
  logits = new_model(images, masks)
  logits = logits.permute(1,0,2,3)
  
  predictions =  torch.nn.functional.softmax(logits[2], dim=0)
  pred_labels = torch.argmax(predictions, dim=0)
  

  prediction = pred_labels.to('cpu').flatten().numpy()
  
  ground_truth = masks[3].to('cpu').flatten().numpy()
  #print(set(prediction))

 

  conf_matrix = skm.multilabel_confusion_matrix(ground_truth, prediction,labels=labels)
  for label in labels:
    stats[label]['tp'] += conf_matrix[label][1][1] 
    stats[label]['fn'] += conf_matrix[label][1][0] 
    stats[label]['fp'] += conf_matrix[label][0][1]

for label in labels:
    tp = stats[label]['tp'] 
    fn = stats[label]['fn'] 
    fp = stats[label]['fp'] 
    iou = tp / ( fp + tp + fn)
    print(f"class {label} iou: {iou}")

